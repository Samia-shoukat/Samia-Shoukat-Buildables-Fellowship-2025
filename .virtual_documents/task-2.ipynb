import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder


dataset = pd.read_csv(r"E:\Assignmnet 1/loan_data.csv")


dataset.head()


dataset.isnull().sum()





le_emp = LabelEncoder()
dataset["Employment_Status"] = le_emp.fit_transform(dataset["Employment_Status"])  
dataset["Text"] = le_emp.fit_transform(dataset["Text"]) 
dataset["Approval"] = dataset["Approval"].map({"Rejected": 0, "Approved": 1})


X = dataset.drop(columns=["Approval"])
y = dataset["Approval"]





X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


rf = RandomForestClassifier()
rf.fit(X_train, y_train)





y_pred = rf.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))





importances = rf.feature_importances_
feature_importance_df = pd.DataFrame({
    "Feature": X.columns,       
    "Importance": importances    
})
feature_importance_df = feature_importance_df.sort_values(by="Importance",ascending=False)


print("Feature Importance:\n")
print(feature_importance_df)


# employment status contribute the most to loan approval in this dataset





plt.figure(figsize=(8,5))
plt.barh(feature_importance_df["Feature"], feature_importance_df["Importance"])
plt.xlabel("Feature Importance")
plt.ylabel("Features")
plt.title("Random Forest Feature Importance for Loan Approval")
plt.gca().invert_yaxis()
plt.show()





train_acc = rf.score(X_train, y_train)
test_acc = rf.score(X_test, y_test)
print("training Accuracy:", train_acc)
print("test Accuracy:", test_acc)


# no overfitting 
