import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc
import matplotlib.pyplot as plt





TP = 50
FP = 30
FN = 10
TN = 110

y_true = np.array([1]*TP + [1]*FN + [0]*FP + [0]*TN)
y_pred = np.array([1]*TP + [0]*FN + [1]*FP + [0]*TN)





accuracy = accuracy_score(y_true, y_pred)
precision = precision_score(y_true, y_pred)
recall = recall_score(y_true, y_pred)
f1 = f1_score(y_true, y_pred)
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)





y_scores = np.array([0.9]*TP+[0.4]*FN+[0.7]*FP+[0.2]*TN)
# Calculate ROC curve
fpr, tpr, thresholds = roc_curve(y_true, y_scores)
roc_auc = auc(fpr, tpr)
plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='red', linestyle='--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate (Recall)")
plt.title("ROC Curve")
plt.legend(loc="lower right")
plt.show()


# AUC score is 0.96 means the model is 96% effective at distinguishing between positive and negative classes





print("Precision:", precision*100)
print("Recall:", recall*100)






